{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!tar -xvf commu_midi.tar"
      ],
      "metadata": {
        "id": "6O-XhTtu8xlX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install music21\n",
        "!pip install miditoolkit\n",
        "!pip install miditok"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-03T18:16:25.746157Z",
          "iopub.execute_input": "2021-09-03T18:16:25.746477Z",
          "iopub.status.idle": "2021-09-03T18:17:10.912698Z",
          "shell.execute_reply.started": "2021-09-03T18:16:25.746406Z",
          "shell.execute_reply": "2021-09-03T18:17:10.911677Z"
        },
        "trusted": true,
        "id": "dVw7D59vA9G4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from io import open\n",
        "import tensorflow as tf\n",
        "import glob\n",
        "import pickle\n",
        "import os\n",
        "import torch\n",
        "import pathlib\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "import time\n",
        "import copy\n",
        "from pathlib import Path, PurePath, PurePosixPath\n",
        "from music21 import converter, instrument, note, chord, stream\n",
        "from miditok import CPWord, REMI\n",
        "from miditok.utils import get_midi_programs\n",
        "from miditoolkit import MidiFile"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2021-09-03T18:17:52.124057Z",
          "iopub.execute_input": "2021-09-03T18:17:52.124427Z",
          "iopub.status.idle": "2021-09-03T18:17:58.125319Z",
          "shell.execute_reply.started": "2021-09-03T18:17:52.124391Z",
          "shell.execute_reply": "2021-09-03T18:17:58.124458Z"
        },
        "trusted": true,
        "id": "b6rgKy5pA9G7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the total amount of dataset"
      ],
      "metadata": {
        "id": "BboYDR4zo8Ts"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = pathlib.Path('commu_midi/train')\n",
        "filenames = glob.glob(str(data_dir/'**/*.mid*'))\n",
        "print('Number of files:', len(filenames))"
      ],
      "metadata": {
        "id": "fofjjzckW1y3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creates the tokenizer and list the file paths"
      ],
      "metadata": {
        "id": "Yqcqy8-OpDXz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "remi_enc = REMI()  # uses defaults parameters\n",
        "files_paths = list(Path(data_dir).glob('**/*.mid*'))\n",
        "print(files_paths)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-03T18:55:21.364985Z",
          "iopub.execute_input": "2021-09-03T18:55:21.365347Z",
          "iopub.status.idle": "2021-09-03T18:55:21.417516Z",
          "shell.execute_reply.started": "2021-09-03T18:55:21.365309Z",
          "shell.execute_reply": "2021-09-03T18:55:21.416677Z"
        },
        "trusted": true,
        "id": "lcZkcxmwA9G8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "midi = MidiFile('commu_midi/train/raw/commu09964.mid')\n",
        "#remi_enc.current_midi_metadata = {'time_divi': midi.ticks_per_beat, 'tempo_changes': midi.tempo_changes}\n",
        "print(midi)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-02T14:28:02.894678Z",
          "iopub.execute_input": "2021-09-02T14:28:02.894996Z",
          "iopub.status.idle": "2021-09-02T14:28:02.906132Z",
          "shell.execute_reply.started": "2021-09-02T14:28:02.894967Z",
          "shell.execute_reply": "2021-09-02T14:28:02.905017Z"
        },
        "trusted": true,
        "id": "MtMMNWvwA9G8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "notes = []\n",
        "n_notes = 0\n",
        "remi_enc = REMI()\n",
        "\n",
        "for f in files_paths:\n",
        "    # read the MIDI file\n",
        "    midi = MidiFile(f)\n",
        "\n",
        "    # Converts MIDI to tokens\n",
        "    tokens = remi_enc(midi)\n",
        "\n",
        "    notes.append(tokens)\n",
        "    n_notes += len(notes)\n",
        "print(\"processed\", n_notes, \"notes\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-03T18:55:25.097544Z",
          "iopub.execute_input": "2021-09-03T18:55:25.097888Z",
          "iopub.status.idle": "2021-09-03T18:55:34.706389Z",
          "shell.execute_reply.started": "2021-09-03T18:55:25.097860Z",
          "shell.execute_reply": "2021-09-03T18:55:34.705490Z"
        },
        "trusted": true,
        "id": "y-wy0uYMA9G9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(notes[0][0])"
      ],
      "metadata": {
        "id": "6agJttLj2Noq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "notes = [note[0] for note in notes]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-03T19:04:46.247805Z",
          "iopub.execute_input": "2021-09-03T19:04:46.248140Z",
          "iopub.status.idle": "2021-09-03T19:04:46.253581Z",
          "shell.execute_reply.started": "2021-09-03T19:04:46.248108Z",
          "shell.execute_reply": "2021-09-03T19:04:46.252611Z"
        },
        "trusted": true,
        "id": "5J94O4CWA9G-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(notes[0])"
      ],
      "metadata": {
        "id": "JUDC16LJ-XP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Dictionary(object):\n",
        "    def __init__(self):\n",
        "        self.word2idx = {}\n",
        "        self.idx2word = []\n",
        "\n",
        "    def add_word(self, word):\n",
        "        if word not in self.word2idx:\n",
        "            self.idx2word.append(word)\n",
        "            self.word2idx[word] = len(self.idx2word) - 1\n",
        "        return self.word2idx[word]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.idx2word)\n",
        "\n",
        "    def words(self):\n",
        "        return self.idx2word\n",
        "\n",
        "\n",
        "class Corpus(object):\n",
        "    def __init__(self, notes, num):\n",
        "        self.dictionary = Dictionary()\n",
        "        self.train = self.tokenize(notes[:-num])\n",
        "        self.valid = self.tokenize(notes[-num:])\n",
        "#         self.test = self.tokenize(notes[-2:])\n",
        "\n",
        "    def tokenize(self, notes):\n",
        "        \"\"\"Tokenizes a note sequence\"\"\"\n",
        "        assert len(notes) > 0\n",
        "\n",
        "        for song in notes:\n",
        "            for note in song:\n",
        "                self.dictionary.add_word(note)\n",
        "                idss = []\n",
        "        for song in notes:\n",
        "            ids = []\n",
        "            for note in song:\n",
        "                ids.append(self.dictionary.word2idx[note])\n",
        "        idss.append(torch.tensor(ids).type(torch.int64))\n",
        "        ids = torch.cat(idss)\n",
        "\n",
        "\n",
        "        return ids"
      ],
      "metadata": {
        "id": "BFdcbridu3I7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = Corpus(notes, 7)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-03T19:04:51.202808Z",
          "iopub.execute_input": "2021-09-03T19:04:51.203153Z",
          "iopub.status.idle": "2021-09-03T19:04:51.297775Z",
          "shell.execute_reply.started": "2021-09-03T19:04:51.203121Z",
          "shell.execute_reply": "2021-09-03T19:04:51.296981Z"
        },
        "trusted": true,
        "id": "XqCdGnAQA9HA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus.train.size(0)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-03T19:06:44.704620Z",
          "iopub.execute_input": "2021-09-03T19:06:44.704966Z",
          "iopub.status.idle": "2021-09-03T19:06:44.711875Z",
          "shell.execute_reply.started": "2021-09-03T19:06:44.704934Z",
          "shell.execute_reply": "2021-09-03T19:06:44.710801Z"
        },
        "trusted": true,
        "id": "9KW-KsT1A9HB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cpu'\n",
        "def batchify(data, bsz):\n",
        "    \"\"\"Divides the data into bsz separate sequences, removing extra elements\n",
        "    that wouldn't cleanly fit.\n",
        "\n",
        "    Args:\n",
        "        data: Tensor, shape [N]\n",
        "        bsz: int, batch size\n",
        "\n",
        "    Returns:\n",
        "        Tensor of shape [N // bsz, bsz]\n",
        "    \"\"\"\n",
        "    seq_len = data.size(0) // bsz\n",
        "    data = data[:seq_len * bsz]\n",
        "    data = data.view(bsz, seq_len).t().contiguous()\n",
        "    return data.to(device)\n",
        "\n",
        "eval_batch_size = 10\n",
        "batch_size = 2\n",
        "train_data = batchify(corpus.train, batch_size)\n",
        "val_data = batchify(corpus.valid, batch_size)\n",
        "# test_data = batchify(corpus.test, batch_size)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-03T19:06:46.503811Z",
          "iopub.execute_input": "2021-09-03T19:06:46.504130Z",
          "iopub.status.idle": "2021-09-03T19:06:46.513420Z",
          "shell.execute_reply.started": "2021-09-03T19:06:46.504100Z",
          "shell.execute_reply": "2021-09-03T19:06:46.512543Z"
        },
        "trusted": true,
        "id": "JanrN5mdA9HB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-03T19:06:47.959752Z",
          "iopub.execute_input": "2021-09-03T19:06:47.960073Z",
          "iopub.status.idle": "2021-09-03T19:06:47.965566Z",
          "shell.execute_reply.started": "2021-09-03T19:06:47.960044Z",
          "shell.execute_reply": "2021-09-03T19:06:47.964671Z"
        },
        "trusted": true,
        "id": "uyN-DIA0A9HB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    \"\"\"Inject some information about the relative or absolute position of the tokens\n",
        "        in the sequence. The positional encodings have the same dimension as\n",
        "        the embeddings, so that the two can be summed. Here, we use sine and cosine\n",
        "        functions of different frequencies.\n",
        "    .. math::\n",
        "        \\text{PosEncoder}(pos, 2i) = sin(pos/10000^(2i/d_model))\n",
        "        \\text{PosEncoder}(pos, 2i+1) = cos(pos/10000^(2i/d_model))\n",
        "        \\text{where pos is the word position and i is the embed idx)\n",
        "    Args:\n",
        "        d_model: the embed dim (required).\n",
        "        dropout: the dropout value (default=0.1).\n",
        "        max_len: the max. length of the incoming sequence (default=5000).\n",
        "    Examples:\n",
        "        >>> pos_encoder = PositionalEncoding(d_model)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        self.d_model = d_model\n",
        "\n",
        "        # PE is the Positional Encoding matrix\n",
        "        # THIS STORES THE POSITIONS OF THE SEQUENCE\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "\n",
        "        # Arange - RETURNS A RANGE BETWEEN VALUES, HERE IT IS 0 - max_len\n",
        "        # unsqueeze - adds a dimension, 1 means that each element in the first list is now in a list\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "\n",
        "        # division term, here it is (10000 ** ((2 * i)/d_model))\n",
        "\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "\n",
        "        # calculating the position encoding for the even and odd terms\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        # Unsqueeze 0 will put PE in one list\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Inputs of forward function\n",
        "        Args:\n",
        "            x: the sequence fed to the positional encoder model (required).\n",
        "        Shape:\n",
        "            x: [sequence length, batch size, embed dim]\n",
        "            output: [sequence length, batch size, embed dim]\n",
        "        Examples:\n",
        "            >>> output = pos_encoder(x)\n",
        "        \"\"\"\n",
        "        # make embeddings relatively larger\n",
        "        # This is so we do not lose the importance of the embedding\n",
        "        x = x * math.sqrt(self.d_model)\n",
        "        # we add the embedding to the PE\n",
        "        x = x + self.pe[:x.size(0), :]\n",
        "        return self.dropout(x)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-29T17:11:28.330626Z",
          "iopub.execute_input": "2021-08-29T17:11:28.330944Z",
          "iopub.status.idle": "2021-08-29T17:11:28.340154Z",
          "shell.execute_reply.started": "2021-08-29T17:11:28.330916Z",
          "shell.execute_reply": "2021-08-29T17:11:28.339348Z"
        },
        "jupyter": {
          "source_hidden": true
        },
        "trusted": true,
        "id": "jcIDqE3iA9HC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\"Parallel self attention given the number of heads and size\n",
        "    .. math::\n",
        "        X * Wk = K\n",
        "        X * Wq = Q\n",
        "        X * Wv = V\n",
        "        \\text{attention} = softmax(Q * transpose(K) / sqrt(d_model)) * V\n",
        "    Args:\n",
        "        d_model: the embed dim (default = 256).\n",
        "        heads: number of heads (default = 4)\n",
        "        max_length = max length of sequences (default = 2048)\n",
        "        dropout: the dropout value (default = 0.1).\n",
        "    Examples:\n",
        "        >>> attention = MultiHeadAttention(d_model, heads)\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model = 256, heads = 4, max_length = 2048, dropout = 0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.d = d_model\n",
        "        self.h = heads\n",
        "        self.dh = d_model // heads\n",
        "        self.max_length = max_length\n",
        "        self.E = torch.randn([heads, self.max_length, self.dh])\n",
        "\n",
        "        self.q_linear = nn.Linear(self.dh, self.dh)\n",
        "        self.v_linear = nn.Linear(self.dh, self.dh)\n",
        "        self.k_linear = nn.Linear(self.dh, self.dh)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.out = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def forward(self, q, k, v, mask=None):\n",
        "\n",
        "        batch_size = q.size(0)\n",
        "        T = q.size(1)\n",
        "        dh = q.size(2) // self.h\n",
        "\n",
        "        k = k.view(batch_size, T, self.h, dh)\n",
        "        q = q.view(batch_size, T, self.h, dh)\n",
        "        v = v.view(batch_size, T, self.h, dh)\n",
        "        # perform linear operation and split into h heads\n",
        "\n",
        "        K = self.k_linear(k)\n",
        "        Q = self.q_linear(q)\n",
        "        V = self.v_linear(v)\n",
        "\n",
        "        # transpose to get dimensions bs * h * sl * d_model\n",
        "\n",
        "        K = K.transpose(1,2)\n",
        "        Q = Q.transpose(1,2)\n",
        "        V = V.transpose(1,2)\n",
        "\n",
        "        #start index of position embedding\n",
        "\n",
        "        embedding_start = self.max_length - T\n",
        "\n",
        "        #apply same position embeddings across the batch\n",
        "\n",
        "        Er  = self.E[:, embedding_start:, :].unsqueeze(0)\n",
        "\n",
        "        QE = torch.matmul(Q, K.transpose(-2, -1))\n",
        "        QE = self.mask_attention_positions(QE)\n",
        "\n",
        "        #Get relative position attention scores\n",
        "        #combine batch with head dimension\n",
        "        SRel = self.skew_padding_position(QE)\n",
        "\n",
        "        #Compute scaled dot-product self-attention\n",
        "        #scale pre-matrix multiplication\n",
        "        Q = Q / (q.size(2) ** (1/4))\n",
        "        K = K / (q.size(2) ** (1/4))\n",
        "\n",
        "        # calculate attention\n",
        "        scores, weights = self.attention(QE, SRel, V, mask, self.dropout)\n",
        "\n",
        "        # concatenate heads and put through final linear layer\n",
        "        concat = scores.transpose(1,2).contiguous().view(batch_size, -1, self.d)\n",
        "\n",
        "        output = self.out(concat)\n",
        "\n",
        "        return output\n",
        "\n",
        "    def attention(self, QE, Srel, V, mask=None, dropout=None):\n",
        "        log = QE + Srel\n",
        "        log = log / math.sqrt(self.dh)\n",
        "\n",
        "        if mask is not None:\n",
        "#             mask = mask.unsqueeze(1)\n",
        "            log += (mask.to(torch.int64) * -1e9).to(log.dtype)\n",
        "\n",
        "#             print(mask.shape)\n",
        "#             log = log.masked_fill(mask == 0, float('-inf'))\n",
        "\n",
        "        scores = F.softmax(log, -1)\n",
        "\n",
        "        if dropout is not None:\n",
        "            scores = dropout(scores)\n",
        "\n",
        "        attention = torch.matmul(scores, V)\n",
        "\n",
        "        return attention, scores\n",
        "\n",
        "    def mask_attention_positions(self, qe):\n",
        "        # to avoid looking backward by masking the positions\n",
        "        index = qe.shape[-1]\n",
        "        mask = torch.triu(torch.ones(index, index), 1).flip(1)\n",
        "        return qe.masked_fill((mask == 1), 0)\n",
        "\n",
        "    def skew_padding_position(self, qe):\n",
        "        # to add padding to the skewed result after masking the matrix\n",
        "        # column of zeros on left\n",
        "        padded_qe = F.pad(qe, [1,0])\n",
        "        s = padded_qe.shape\n",
        "        padded_qe = padded_qe.view(s[0], s[1], s[3], s[2])\n",
        "        #take out first (padded) row\n",
        "        return padded_qe[:,:,1:,:]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-29T17:11:29.221271Z",
          "iopub.execute_input": "2021-08-29T17:11:29.221605Z",
          "iopub.status.idle": "2021-08-29T17:11:29.240108Z",
          "shell.execute_reply.started": "2021-08-29T17:11:29.221574Z",
          "shell.execute_reply": "2021-08-29T17:11:29.239141Z"
        },
        "jupyter": {
          "source_hidden": true
        },
        "trusted": true,
        "id": "78O8g8t3A9HC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, d_model, d_ff=2048, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.linear_1 = nn.Linear(d_model, d_ff)\n",
        "        self.linear_2 = nn.Linear(d_ff, d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear_2(self.dropout(F.relu(self.linear_1(x))))\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-29T17:11:29.51977Z",
          "iopub.execute_input": "2021-08-29T17:11:29.520083Z",
          "iopub.status.idle": "2021-08-29T17:11:29.525789Z",
          "shell.execute_reply.started": "2021-08-29T17:11:29.520034Z",
          "shell.execute_reply": "2021-08-29T17:11:29.524865Z"
        },
        "jupyter": {
          "source_hidden": true
        },
        "trusted": true,
        "id": "x5xcx9a9A9HD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build an encoder layer with one multi-head attention layer and one # feed-forward layer\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, heads, dropout = 0.1):\n",
        "        super().__init__()\n",
        "        self.norm_1 = nn.LayerNorm(d_model)\n",
        "        self.norm_2 = nn.LayerNorm(d_model)\n",
        "\n",
        "        self.attn = MultiHeadAttention(d_model, heads)\n",
        "        self.ff = FeedForward(d_model)\n",
        "        self.dropout_1 = nn.Dropout(dropout)\n",
        "        self.dropout_2 = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        x2 = self.norm_1(x)\n",
        "        x = x + self.dropout_1(self.attn(x2,x2,x2,mask))\n",
        "        x2 = self.norm_2(x)\n",
        "        x = x + self.dropout_2(self.ff(x2))\n",
        "        return x\n",
        "\n",
        "# build a decoder layer with two multi-head attention layers and\n",
        "# one feed-forward layer\n",
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, heads, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.norm_1 = nn.LayerNorm(d_model)\n",
        "        self.norm_2 = nn.LayerNorm(d_model)\n",
        "        self.norm_3 = nn.LayerNorm(d_model)\n",
        "\n",
        "        self.dropout_1 = nn.Dropout(dropout)\n",
        "        self.dropout_2 = nn.Dropout(dropout)\n",
        "        self.dropout_3 = nn.Dropout(dropout)\n",
        "\n",
        "        self.attn_1 = MultiHeadAttention(d_model, heads)\n",
        "        self.attn_2 = MultiHeadAttention(d_model, heads)\n",
        "        self.ff = FeedForward(d_model)\n",
        "    def forward(self, x, memory, mask = None):\n",
        "        #perform masked attention on input\n",
        "        #masked so queries cannot attend to subsequent keys\n",
        "        #Pass through sublayers of attention and feedforward.\n",
        "        #Apply dropout to sublayer output, add it to input, and norm.\n",
        "        attn = self.attn_1(x, x, x, mask)\n",
        "        x = x + self.dropout_1(attn)\n",
        "        x = self.norm_1(x)\n",
        "        x = x + self.dropout_2(self.attn_2(x, memory, memory, mask))\n",
        "        ff = self.ff(x)\n",
        "        x = x + self.dropout_2(ff)\n",
        "        x = self.norm_2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# We can then build a convenient cloning function that can generate multiple layers:\n",
        "def get_clones(module, N):\n",
        "    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-29T17:11:29.785832Z",
          "iopub.execute_input": "2021-08-29T17:11:29.786141Z",
          "iopub.status.idle": "2021-08-29T17:11:29.802339Z",
          "shell.execute_reply.started": "2021-08-29T17:11:29.786111Z",
          "shell.execute_reply": "2021-08-29T17:11:29.801479Z"
        },
        "jupyter": {
          "source_hidden": true
        },
        "trusted": true,
        "id": "qlNWzzgCA9HD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, d_model, N, heads):\n",
        "        super().__init__()\n",
        "        self.N = N\n",
        "        self.layers = get_clones(EncoderLayer(d_model, heads), self.N)\n",
        "        self.norm = nn.LayerNorm(d_model)\n",
        "    def forward(self, src, mask):\n",
        "        x = self.layers[0](src, mask)\n",
        "        for i in range(1,self.N):\n",
        "            x = self.layers[i](x, mask)\n",
        "        return self.norm(x)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model, N, heads):\n",
        "        super().__init__()\n",
        "        self.N = N\n",
        "        self.layers = get_clones(DecoderLayer(d_model, heads), N)\n",
        "        self.norm = nn.LayerNorm(d_model)\n",
        "    def forward(self, src, trg, src_mask = None):\n",
        "        x = self.layers[0](src, trg, src_mask)\n",
        "        for i in range(1,self.N):\n",
        "            x = self.layers[i](x, trg, src_mask)\n",
        "        return self.norm(x)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-29T17:11:30.089969Z",
          "iopub.execute_input": "2021-08-29T17:11:30.090276Z",
          "iopub.status.idle": "2021-08-29T17:11:30.099241Z",
          "shell.execute_reply.started": "2021-08-29T17:11:30.090245Z",
          "shell.execute_reply": "2021-08-29T17:11:30.09815Z"
        },
        "jupyter": {
          "source_hidden": true
        },
        "trusted": true,
        "id": "Zw0derLoA9HE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerModel(nn.Module):\n",
        "    \"\"\"Container module with an encoder, a recurrent or transformer module, and a decoder.\"\"\"\n",
        "\n",
        "    def __init__(self, ntoken, d_model, nhead, nhid, nlayers, dropout=0.5, max_length = 2048):\n",
        "        super(TransformerModel, self).__init__()\n",
        "        try:\n",
        "            from torch.nn import TransformerEncoder, TransformerEncoderLayer, TransformerDecoder, TransformerDecoderLayer\n",
        "        except:\n",
        "            raise ImportError('TransformerEncoder module does not exist in PyTorch 1.1 or lower.')\n",
        "        self.model_type = 'Transformer'\n",
        "        # original mask\n",
        "        self.src_mask = None\n",
        "        self.max_length = max_length\n",
        "        self.d_model = d_model\n",
        "\n",
        "        # embedding encoding\n",
        "        self.embedding = nn.Embedding(ntoken, d_model)\n",
        "\n",
        "        # positional encoding\n",
        "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
        "\n",
        "        # encoder\n",
        "        encoder_layers = TransformerEncoderLayer(d_model, nhead, nhid, dropout)\n",
        "        self.encoder = TransformerEncoder(encoder_layers, nlayers)\n",
        "\n",
        "        # decoder\n",
        "        decoder_layers = TransformerDecoderLayer(d_model, nhead, nhid, dropout)\n",
        "        self.decoder = TransformerDecoder(decoder_layers, nlayers)\n",
        "\n",
        "        # classification layer\n",
        "        self.classification_layer = nn.Linear(d_model, ntoken)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def _generate_square_subsequent_mask(self, sz):\n",
        "\n",
        "        mask = torch.triu(torch.ones(sz, sz) * float('-inf'), diagonal=1)\n",
        "#         mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "#         mask = utils.get_masked_with_pad_tensor(self.max_length, x, x, config.pad_token)\n",
        "        return mask\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        nn.init.uniform_(self.embedding.weight, -initrange, initrange)\n",
        "        self.classification_layer.bias.data.zero_()\n",
        "        self.classification_layer.weight.data.uniform_(-initrange, initrange)\n",
        "#         nn.init.zeros_(self.decoder.weight)\n",
        "#         nn.init.uniform_(self.decoder.weight, -initrange, initrange)\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "\n",
        "        if src_mask == None:\n",
        "            src_mask = self._generate_square_subsequent_mask(len(src))\n",
        "        self.src_mask = src_mask\n",
        "\n",
        "        src = self.pos_encoder(self.embedding(src))\n",
        "        output = self.encoder(src, self.src_mask)\n",
        "        output = self.decoder(output, src)\n",
        "        output = self.classification_layer(output)\n",
        "        return F.log_softmax(output, dim=-1)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-03T19:06:55.514055Z",
          "iopub.execute_input": "2021-09-03T19:06:55.514410Z",
          "iopub.status.idle": "2021-09-03T19:06:55.527460Z",
          "shell.execute_reply.started": "2021-09-03T19:06:55.514376Z",
          "shell.execute_reply": "2021-09-03T19:06:55.526512Z"
        },
        "trusted": true,
        "id": "BU2yGXP8A9HE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(corpus.dictionary)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-03T19:06:56.945072Z",
          "iopub.execute_input": "2021-09-03T19:06:56.945411Z",
          "iopub.status.idle": "2021-09-03T19:06:56.950169Z",
          "shell.execute_reply.started": "2021-09-03T19:06:56.945379Z",
          "shell.execute_reply": "2021-09-03T19:06:56.949391Z"
        },
        "trusted": true,
        "id": "8kP1QFbKA9HF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parameters definition"
      ],
      "metadata": {
        "id": "8DhYgL18LRo-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ntokens = len(corpus.dictionary)\n",
        "emsize = 200\n",
        "nhead = 2\n",
        "nhid = 200\n",
        "nlayer = 2\n",
        "dropout = 0.2\n",
        "# Loop over epochs.\n",
        "lr = 0.005\n",
        "best_val_loss = None\n",
        "epochs = 100\n",
        "save = './model.pt'\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-03T19:06:58.204029Z",
          "iopub.execute_input": "2021-09-03T19:06:58.204363Z",
          "iopub.status.idle": "2021-09-03T19:06:58.209396Z",
          "shell.execute_reply.started": "2021-09-03T19:06:58.204330Z",
          "shell.execute_reply": "2021-09-03T19:06:58.208576Z"
        },
        "trusted": true,
        "id": "6Y4uBG8TA9HF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_losses = []\n",
        "emsizes = []\n",
        "nheads = []\n",
        "nhids = []\n",
        "nlayers = []\n",
        "\n",
        "for em in emsizes:\n",
        "    for head in nhead:\n",
        "        for hid in nhid:\n",
        "            for layer in nlayer:\n",
        "                emsizes.append(em)\n",
        "                nheads.append(head)\n",
        "                nhids.append(hid)\n",
        "                nlayers.append(layer)\n",
        "                best_val_loss = None\n",
        "\n",
        "                model = TransformerModel(ntokens, em, head, hid, layer, dropout).to(device)\n",
        "\n",
        "                # At any point you can hit Ctrl + C to break out of training early.\n",
        "                try:\n",
        "                    for epoch in range(1, epochs+1):\n",
        "                        epoch_start_time = time.time()\n",
        "                        train()\n",
        "                        val_loss = evaluate(test_data)\n",
        "                        train_loss = evaluate(train_data)\n",
        "                        print('-' * 89)\n",
        "                        print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | train loss {:5.2f}'\n",
        "                                'valid ppl {:8.2f}'.format(epoch, (time.time() - epoch_start_time),\n",
        "                                                           val_loss, train_loss, math.exp(val_loss)))\n",
        "                        print('-' * 89)\n",
        "                        # Save the model if the validation loss is the best we've seen so far.\n",
        "                        if not best_val_loss or val_loss < best_val_loss:\n",
        "                            with open(save, 'wb') as f:\n",
        "                                torch.save(model, f)\n",
        "                            best_val_loss = val_loss\n",
        "                        else:\n",
        "                            # Anneal the learning rate if no improvement has been seen in the validation dataset.\n",
        "                            lr /= 2.0\n",
        "                except KeyboardInterrupt:\n",
        "                    print('-' * 89)\n",
        "                    print('Exiting from training early')\n",
        "                final_losses.append(best_val_loss)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-29T18:56:39.549881Z",
          "iopub.execute_input": "2021-08-29T18:56:39.550198Z",
          "iopub.status.idle": "2021-08-29T18:56:39.581371Z",
          "shell.execute_reply.started": "2021-08-29T18:56:39.550154Z",
          "shell.execute_reply": "2021-08-29T18:56:39.580269Z"
        },
        "jupyter": {
          "source_hidden": true
        },
        "trusted": true,
        "id": "jQMMTjY9A9HF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "JzugfnW7A9HG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = TransformerModel(ntokens, emsize, nhead, nhid, nlayer, dropout).to(device)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-03T19:07:03.722853Z",
          "iopub.execute_input": "2021-09-03T19:07:03.723193Z",
          "iopub.status.idle": "2021-09-03T19:07:03.813281Z",
          "shell.execute_reply.started": "2021-09-03T19:07:03.723157Z",
          "shell.execute_reply": "2021-09-03T19:07:03.812372Z"
        },
        "trusted": true,
        "id": "HHoD2ZDtA9HH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def repackage_hidden(h):\n",
        "    \"\"\"Wraps hidden states in new Tensors, to detach them from their history.\"\"\"\n",
        "\n",
        "    if isinstance(h, torch.Tensor):\n",
        "        return h.detach()\n",
        "    else:\n",
        "        return tuple(repackage_hidden(v) for v in h)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-03T19:07:04.601526Z",
          "iopub.execute_input": "2021-09-03T19:07:04.601856Z",
          "iopub.status.idle": "2021-09-03T19:07:04.606057Z",
          "shell.execute_reply.started": "2021-09-03T19:07:04.601824Z",
          "shell.execute_reply": "2021-09-03T19:07:04.605228Z"
        },
        "trusted": true,
        "id": "2W8DBtjGA9HI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get_batch subdivides the source data into chunks of length args.bptt.\n",
        "# If source is equal to the example output of the batchify function, with\n",
        "# a bptt-limit of 2, we'd get the following two Variables for i = 0:\n",
        "# ┌ a g m s ┐ ┌ b h n t ┐\n",
        "# └ b h n t ┘ └ c i o u ┘\n",
        "# Note that despite the name of the function, the subdivison of data is not\n",
        "# done along the batch dimension (i.e. dimension 1), since that was handled\n",
        "# by the batchify function. The chunks are along dimension 0, corresponding\n",
        "# to the seq_len dimension in the LSTM.\n",
        "seq_length = 35\n",
        "def get_batch(source, i):\n",
        "    seq_len = min(seq_length, len(source) - 1 - i)\n",
        "    data = source[i:i+seq_len]\n",
        "    target = source[i+1:i+1+seq_len].reshape(-1)\n",
        "    return data, target"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-03T19:07:05.414726Z",
          "iopub.execute_input": "2021-09-03T19:07:05.415051Z",
          "iopub.status.idle": "2021-09-03T19:07:05.420368Z",
          "shell.execute_reply.started": "2021-09-03T19:07:05.415023Z",
          "shell.execute_reply": "2021-09-03T19:07:05.419407Z"
        },
        "trusted": true,
        "id": "bwdaj5TLA9HI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_square_subsequent_mask(sz):\n",
        "    \"\"\"Generates an upper-triangular matrix of -inf, with zeros on diag.\"\"\"\n",
        "    return torch.triu(torch.ones(sz, sz) * float('-inf'), diagonal=1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-03T19:07:05.953674Z",
          "iopub.execute_input": "2021-09-03T19:07:05.954001Z",
          "iopub.status.idle": "2021-09-03T19:07:05.958595Z",
          "shell.execute_reply.started": "2021-09-03T19:07:05.953966Z",
          "shell.execute_reply": "2021-09-03T19:07:05.957690Z"
        },
        "trusted": true,
        "id": "NRuWhjdWA9HJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, eval_data):\n",
        "    model.eval()  # turn on evaluation mode\n",
        "    total_loss = 0.\n",
        "    src_mask = generate_square_subsequent_mask(seq_length).to(device)\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, eval_data.size(0) - 1, seq_length):\n",
        "            data, targets = get_batch(eval_data, i)\n",
        "            batch_size = data.size(0)\n",
        "            if batch_size != seq_length:\n",
        "                src_mask = src_mask[:batch_size, :batch_size]\n",
        "            output = model(data, src_mask)\n",
        "            output_flat = output.view(-1, ntokens)\n",
        "            total_loss += batch_size * criterion(output_flat, targets).item()\n",
        "    return total_loss / (len(eval_data) - 1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-03T19:07:06.874746Z",
          "iopub.execute_input": "2021-09-03T19:07:06.875099Z",
          "iopub.status.idle": "2021-09-03T19:07:06.881794Z",
          "shell.execute_reply.started": "2021-09-03T19:07:06.875070Z",
          "shell.execute_reply": "2021-09-03T19:07:06.880758Z"
        },
        "trusted": true,
        "id": "I0md5Nq-A9HJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n",
        "\n",
        "def train(model):\n",
        "    model.train()  # turn on train mode\n",
        "    total_loss = 0.\n",
        "    log_interval = 200\n",
        "    start_time = time.time()\n",
        "    src_mask = generate_square_subsequent_mask(seq_length).to(device)\n",
        "\n",
        "    num_batches = len(train_data) // seq_length\n",
        "    for batch, i in enumerate(range(0, train_data.size(0) - 1, seq_length)):\n",
        "        data, targets = get_batch(train_data, i)\n",
        "        batch_size = data.size(0)\n",
        "        if batch_size != seq_length:  # only on last batch\n",
        "            src_mask = src_mask[:batch_size, :batch_size]\n",
        "        output = model(data, src_mask)\n",
        "        loss = criterion(output.view(-1, ntokens), targets)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        if batch % log_interval == 0 and batch > 0:\n",
        "            lr = scheduler.get_last_lr()[0]\n",
        "            ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n",
        "            cur_loss = total_loss / log_interval\n",
        "            ppl = math.exp(cur_loss)\n",
        "            print(f'| epoch {epoch:3d} | {batch:5d}/{num_batches:5d} batches | '\n",
        "                  f'lr {lr:02.2f} | ms/batch {ms_per_batch:5.2f} | '\n",
        "                  f'loss {cur_loss:5.2f} | ppl {ppl:8.2f}')\n",
        "            total_loss = 0\n",
        "            start_time = time.time()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-03T19:07:07.703171Z",
          "iopub.execute_input": "2021-09-03T19:07:07.703560Z",
          "iopub.status.idle": "2021-09-03T19:07:07.716217Z",
          "shell.execute_reply.started": "2021-09-03T19:07:07.703526Z",
          "shell.execute_reply": "2021-09-03T19:07:07.714933Z"
        },
        "trusted": true,
        "id": "rTlQXqO8A9HJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import math\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "try:\n",
        "    for epoch in range(1, epochs+1):\n",
        "        epoch_start_time = time.time()\n",
        "        train(model)\n",
        "        val_loss = evaluate(model, val_data)\n",
        "        val_losses.append(val_loss)\n",
        "        train_loss = evaluate(model, train_data)\n",
        "        train_losses.append(train_loss)\n",
        "        print('-' * 89)\n",
        "        print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | train loss {:5.2f} | '\n",
        "                'valid ppl {:8.2f}'.format(epoch, (time.time() - epoch_start_time),\n",
        "                                           val_loss, train_loss, math.exp(val_loss)))\n",
        "        print('-' * 89)\n",
        "        # Save the model if the validation loss is the best we've seen so far.\n",
        "        if not best_val_loss or val_loss < best_val_loss:\n",
        "            with open(save, 'wb') as f:\n",
        "                torch.save(model, f)\n",
        "            best_val_loss = val_loss\n",
        "        else:\n",
        "            # Anneal the learning rate if no improvement has been seen in the validation dataset.\n",
        "            lr /= 2.0\n",
        "\n",
        "        # Plot the training and validation losses\n",
        "    plt.plot(train_losses, label='Training Loss')\n",
        "    plt.plot(val_losses, label='Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training and Validation Losses')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "except KeyboardInterrupt:\n",
        "    print('-' * 89)\n",
        "    print('Exiting from training early')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-03T19:07:08.886100Z",
          "iopub.execute_input": "2021-09-03T19:07:08.886463Z",
          "iopub.status.idle": "2021-09-03T19:08:25.356123Z",
          "shell.execute_reply.started": "2021-09-03T19:07:08.886429Z",
          "shell.execute_reply": "2021-09-03T19:08:25.355181Z"
        },
        "trusted": true,
        "id": "0BlGiBu8A9HJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "metadata": {
        "id": "_6I0UfCAr80V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters(model):\n",
        "    total_params = 0\n",
        "    for name, param in model.named_parameters():\n",
        "        if param.requires_grad:\n",
        "            num_params = param.numel()\n",
        "            print(f\"{name}: {num_params}\")\n",
        "            total_params += num_params\n",
        "    print(f\"Total Parameters: {total_params}\")\n",
        "\n",
        "count_parameters(model)"
      ],
      "metadata": {
        "id": "EYFgXU_MWpg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_generate = 2000\n",
        "temperature = 1\n",
        "sequence = []\n",
        "log_interval = 50 # interval between logs"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-03T19:25:01.640869Z",
          "iopub.execute_input": "2021-09-03T19:25:01.641340Z",
          "iopub.status.idle": "2021-09-03T19:25:01.646024Z",
          "shell.execute_reply.started": "2021-09-03T19:25:01.641282Z",
          "shell.execute_reply": "2021-09-03T19:25:01.645124Z"
        },
        "trusted": true,
        "id": "s_ToslwHA9HK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "input = torch.randint(ntokens, (1, 1), dtype=torch.long).to(device)\n",
        "src_mask = generate_square_subsequent_mask(len(input)).to(device)\n",
        "with open('./output', 'w') as outf:\n",
        "    with torch.no_grad():  # no tracking history\n",
        "        for i in range(n_generate):\n",
        "            src_mask = generate_square_subsequent_mask(len(input)).to(device)\n",
        "            output = model(input, src_mask)\n",
        "            word_weights = output[-1].squeeze().div(temperature).exp().cpu()\n",
        "            word_idx = torch.multinomial(word_weights, 1)[0]\n",
        "            word_tensor = torch.Tensor([[word_idx]]).long().to(device)\n",
        "            input = torch.cat([input, word_tensor], 0)\n",
        "\n",
        "\n",
        "            word = corpus.dictionary.idx2word[word_idx]\n",
        "\n",
        "            outf.write(str(word) + ('\\n' if i % 20 == 19 else ' '))\n",
        "\n",
        "            sequence.append(word)\n",
        "\n",
        "            if i % log_interval == 0:\n",
        "                print('| Generated {}/{} notes'.format(i, n_generate))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-03T19:25:02.714654Z",
          "iopub.execute_input": "2021-09-03T19:25:02.715000Z",
          "iopub.status.idle": "2021-09-03T19:31:29.512435Z",
          "shell.execute_reply.started": "2021-09-03T19:25:02.714968Z",
          "shell.execute_reply": "2021-09-03T19:31:29.511549Z"
        },
        "trusted": true,
        "id": "mO-0I5kjA9HK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequence = [sequence]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-03T19:42:23.052259Z",
          "iopub.execute_input": "2021-09-03T19:42:23.052674Z",
          "iopub.status.idle": "2021-09-03T19:42:23.059190Z",
          "shell.execute_reply.started": "2021-09-03T19:42:23.052640Z",
          "shell.execute_reply": "2021-09-03T19:42:23.058369Z"
        },
        "trusted": true,
        "id": "qv_DQMENA9HL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "remi_enc = REMI()"
      ],
      "metadata": {
        "id": "XXndKXxorDbF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "converted_back_midi = remi_enc.tokens_to_midi(sequence)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-03T19:42:24.306695Z",
          "iopub.execute_input": "2021-09-03T19:42:24.307023Z",
          "iopub.status.idle": "2021-09-03T19:42:24.314384Z",
          "shell.execute_reply.started": "2021-09-03T19:42:24.306992Z",
          "shell.execute_reply": "2021-09-03T19:42:24.313082Z"
        },
        "trusted": true,
        "id": "v1BXO8kNA9HL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "converted_back_midi.dump_midi('generated_music.mid')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-03T19:42:37.464140Z",
          "iopub.execute_input": "2021-09-03T19:42:37.464496Z",
          "iopub.status.idle": "2021-09-03T19:42:37.469033Z",
          "shell.execute_reply.started": "2021-09-03T19:42:37.464464Z",
          "shell.execute_reply": "2021-09-03T19:42:37.467973Z"
        },
        "trusted": true,
        "id": "fdnydJ5mA9HL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pretty_midi"
      ],
      "metadata": {
        "id": "ii39RddMllg2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pretty_midi"
      ],
      "metadata": {
        "id": "gNiLM7k-mLvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_file = \"commu_midi/train/raw/commu09974.mid\"   # You can also put filenames[index]\n",
        "generated_file = \"generated_music.mid\""
      ],
      "metadata": {
        "id": "su4-pR3SnToF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pm = pretty_midi.PrettyMIDI(generated_file)\n",
        "print('Number of instruments:', len(pm.instruments))\n",
        "instrument = pm.instruments[0]\n",
        "instrument_name = pretty_midi.program_to_instrument_name(instrument.program)\n",
        "print('Instrument name:', instrument_name)"
      ],
      "metadata": {
        "id": "ccc_vbxCmBDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, note in enumerate(instrument.notes[:10]):\n",
        "  note_name = pretty_midi.note_number_to_name(note.pitch)\n",
        "  duration = note.end - note.start\n",
        "  print(f'{i}: pitch={note.pitch}, note_name={note_name},'\n",
        "        f' duration={duration:.4f}')"
      ],
      "metadata": {
        "id": "1UD5qeWZkm13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "def midi_to_notes(midi_file: str) -> pd.DataFrame:\n",
        "    pm = pretty_midi.PrettyMIDI(midi_file) #initializes a PrettyMIDI object (pm) using the provided MIDI file.\n",
        "    instrument = pm.instruments[0]\n",
        "    notes = collections.defaultdict(list)\n",
        "\n",
        "    sorted_notes = sorted(instrument.notes, key=lambda note: note.start)\n",
        "    prev_start = sorted_notes[0].start\n",
        "\n",
        "    for note in sorted_notes:\n",
        "        start = note.start\n",
        "        end = note.end\n",
        "        notes['pitch'].append(note.pitch)\n",
        "        notes['start'].append(start)\n",
        "        notes['end'].append(end)\n",
        "        notes['step'].append(start - prev_start)\n",
        "        notes['duration'].append(end - start)\n",
        "        prev_start = start\n",
        "\n",
        "    return pd.DataFrame({name : np.array(value) for name, value in notes.items()})"
      ],
      "metadata": {
        "id": "GGZwRWkjm4B7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generated_notes = midi_to_notes(generated_file)\n",
        "sample_notes = midi_to_notes(sample_file)\n",
        "generated_notes.head()"
      ],
      "metadata": {
        "id": "_TXgngjtm7Xr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict, List, Optional, Sequence, Tuple\n",
        "def plot_piano_roll(notes: pd.DataFrame, count: Optional[int] = None):\n",
        "  if count:\n",
        "    title = f'First {count} notes'\n",
        "  else:\n",
        "    title = f'Whole track'\n",
        "    count = len(notes['pitch'])\n",
        "  plt.figure(figsize=(20, 4))\n",
        "  plot_pitch = np.stack([notes['pitch'], notes['pitch']], axis=0)\n",
        "  plot_start_stop = np.stack([notes['start'], notes['end']], axis=0)\n",
        "  plt.plot(\n",
        "      plot_start_stop[:, :count], plot_pitch[:, :count], color=\"b\", marker=\".\")\n",
        "  plt.xlabel('Time [s]')\n",
        "  plt.ylabel('Pitch')\n",
        "  _ = plt.title(title)"
      ],
      "metadata": {
        "id": "ZppYfm62iKLF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_piano_roll(generated_notes)"
      ],
      "metadata": {
        "id": "8G6dukKcmgSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "def plot_distributions(notes: pd.DataFrame, drop_percentile=2.5):\n",
        "  plt.figure(figsize=[15, 5])\n",
        "  plt.subplot(1, 3, 1)\n",
        "  sns.histplot(notes, x=\"pitch\", bins=20)\n",
        "\n",
        "  plt.subplot(1, 3, 2)\n",
        "  max_step = np.percentile(notes['step'], 100 - drop_percentile)\n",
        "  sns.histplot(notes, x=\"step\", bins=np.linspace(0, max_step, 21))\n",
        "\n",
        "  plt.subplot(1, 3, 3)\n",
        "  max_duration = np.percentile(notes['duration'], 100 - drop_percentile)\n",
        "  sns.histplot(notes, x=\"duration\", bins=np.linspace(0, max_duration, 21))\n"
      ],
      "metadata": {
        "id": "R2Aprd-kmp5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_distributions(generated_notes)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "y8S0cy-0n9y2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import music21\n",
        "\n",
        "def extract_notes(midi_file):\n",
        "    # Parse the MIDI file and extract notes\n",
        "    midi_stream = music21.converter.parse(midi_file)\n",
        "    notes = []\n",
        "    for element in midi_stream.flat.notesAndRests:\n",
        "        # Check if the element is a chord\n",
        "        if isinstance(element, music21.chord.Chord):\n",
        "            # Extract pitches of individual notes in the chord\n",
        "            for note in element:\n",
        "                note_features = {\n",
        "                    'pitch': note.pitch.ps,  # Convert pitch to MIDI pitch value\n",
        "                    'duration': element.duration.quarterLength  # Duration in quarter note units\n",
        "                    # Add other relevant features as needed\n",
        "                }\n",
        "                notes.append(note_features)\n",
        "        elif isinstance(element, music21.note.Note):\n",
        "            # Extract relevant features of the note\n",
        "            note_features = {\n",
        "                'pitch': element.pitch.ps,  # Convert pitch to MIDI pitch value\n",
        "                'duration': element.duration.quarterLength  # Duration in quarter note units\n",
        "                # Add other relevant features as needed\n",
        "            }\n",
        "            notes.append(note_features)\n",
        "    return notes\n",
        "\n",
        "def calculate_mse(sample_notes, extracted_notes):\n",
        "    # Ensure sequences have the same length\n",
        "    min_length = min(len(sample_notes), len(extracted_notes))\n",
        "    sample_notes = sample_notes[:min_length]\n",
        "    extracted_notes = extracted_notes[:min_length]\n",
        "\n",
        "    # Compute squared differences\n",
        "    squared_diffs = [\n",
        "        (sample_note['pitch'] - extracted_note['pitch']) ** 2 +\n",
        "        (sample_note['duration'] - extracted_note['duration']) ** 2\n",
        "        # Add squared differences for other features as needed\n",
        "        for sample_note, extracted_note in zip(sample_notes, extracted_notes)\n",
        "    ]\n",
        "\n",
        "    # Compute mean squared error\n",
        "    mse = sum(squared_diffs) / len(squared_diffs)\n",
        "\n",
        "    return mse\n",
        "\n",
        "sample_notes = extract_notes(sample_file)\n",
        "extracted_notes = extract_notes(generated_file)\n",
        "\n",
        "mse = calculate_mse(sample_notes, extracted_notes)\n",
        "print(\"Mean Squared Error:\", mse)\n"
      ],
      "metadata": {
        "id": "AdULTiUpoJSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I7eganTjxB9H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}